{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Using cached https://files.pythonhosted.org/packages/96/84/4e2cae6247f397f83d8adc5c2a2a0c5d7d790a14a4c7400ff6574586f589/xgboost-0.90.tar.gz\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('VTI.csv')\n",
    "#df.isnull().values.any()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "def get_preds_lin_reg(df, target_col, N, pred_min, offset):\n",
    "    \"\"\"\n",
    "    Given a dataframe, get prediction at each timestep\n",
    "    Inputs\n",
    "        df         : dataframe with the values you want to predict     \n",
    "        target_col : name of the column you want to predict\n",
    "        N          : use previous N values to do prediction\n",
    "        pred_min   : all predictions should be >= pred_min\n",
    "        offset     : for df we only do predictions for df[offset:]\n",
    "    Outputs\n",
    "        pred_list  : the predictions for target_col\n",
    "    \"\"\"\n",
    "    # Create linear regression object\n",
    "    regr = LinearRegression(fit_intercept=True)\n",
    "    pred_list = []\n",
    "    for i in range(offset, len(df['Adj Close'])):\n",
    "        X_train = np.array(range(len(df['Adj Close'][i-N:i]))) \n",
    "        y_train = np.array(df['Adj Close'][i-N:i]) \n",
    "        X_train = X_train.reshape(-1, 1)     \n",
    "        y_train = y_train.reshape(-1, 1)\n",
    "        regr.fit(X_train, y_train)            # Train the model\n",
    "        pred = regr.predict(N)\n",
    "    \n",
    "        pred_list.append(pred[0][0])  \n",
    "    \n",
    "    # If the values are < pred_min, set it to be pred_min\n",
    "    pred_list = np.array(pred_list)\n",
    "    pred_list[pred_list < pred_min] = pred_min\n",
    "        \n",
    "    return pred_list\n",
    "print(get_preds_lin_reg(df, df['Close'],df['Open'] ,df['Low'], 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "def get_mape(y_true, y_pred): \n",
    "    \"\"\"\n",
    "    Compute mean absolute percentage error (MAPE)\n",
    "    \"\"\"\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "def train_pred_eval_model(X_train_scaled, \\\n",
    "                          y_train_scaled, \\\n",
    "                          X_test_scaled, \\\n",
    "                          y_test, \\\n",
    "                          col_mean, \\\n",
    "                          col_std, \\\n",
    "                          seed=100, \\\n",
    "                          n_estimators=100, \\\n",
    "                          max_depth=3, \\\n",
    "                          learning_rate=0.1, \\\n",
    "                          min_child_weight=1, \\\n",
    "                          subsample=1, \\\n",
    "                          colsample_bytree=1, \\\n",
    "                          colsample_bylevel=1, \\\n",
    "                          gamma=0):\n",
    "    '''\n",
    "    Train model, do prediction, scale back to original range and do \n",
    "    evaluation\n",
    "    Use XGBoost here.\n",
    "    Inputs\n",
    "        X_train_scaled     : features for training. Scaled to have \n",
    "                             mean 0 and variance 1\n",
    "        y_train_scaled     : target for training. Scaled to have \n",
    "                             mean 0 and variance 1\n",
    "        X_test_scaled      : features for test. Each sample is \n",
    "                             scaled to mean 0 and variance 1\n",
    "        y_test             : target for test. Actual values, not \n",
    "                             scaled\n",
    "        col_mean           : means used to scale each sample of \n",
    "                             X_test_scaled. Same length as \n",
    "                             X_test_scaled and y_test\n",
    "        col_std            : standard deviations used to scale each \n",
    "                             sample of X_test_scaled. Same length as \n",
    "                             X_test_scaled and y_test\n",
    "        seed               : model seed\n",
    "        n_estimators       : number of boosted trees to fit\n",
    "        max_depth          : maximum tree depth for base learners\n",
    "        learning_rate      : boosting learning rate (xgb’s “eta”)\n",
    "        min_child_weight   : minimum sum of instance weight(hessian) \n",
    "                             needed in a child\n",
    "        subsample          : subsample ratio of the training \n",
    "                             instance\n",
    "        colsample_bytree   : subsample ratio of columns when \n",
    "                             constructing each tree\n",
    "        colsample_bylevel  : subsample ratio of columns for each \n",
    "                             split, in each level\n",
    "        gamma              : minimum loss reduction required to make \n",
    "                             a further partition on a leaf node of \n",
    "                             the tree\n",
    "    Outputs\n",
    "        rmse               : root mean square error of y_test and \n",
    "                             est\n",
    "        mape               : mean absolute percentage error of \n",
    "                             y_test and est\n",
    "        est                : predicted values. Same length as y_test\n",
    "    '''\n",
    "    model = XGBRegressor(seed=model_seed,\n",
    "                         n_estimators=n_estimators,\n",
    "                         max_depth=max_depth,\n",
    "                         learning_rate=learning_rate,\n",
    "                         min_child_weight=min_child_weight,\n",
    "                         subsample=subsample,\n",
    "                         colsample_bytree=colsample_bytree,\n",
    "                         colsample_bylevel=colsample_bylevel,\n",
    "                         gamma=gamma)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_scaled, y_train_scaled)\n",
    "    \n",
    "    # Get predicted labels and scale back to original range\n",
    "    est_scaled = model.predict(X_test_scaled)\n",
    "    est = est_scaled * col_std + col_mean\n",
    "    # Calculate RMSE\n",
    "    rmse = math.sqrt(mean_squared_error(y_test, est))\n",
    "    mape = get_mape(y_test, est)\n",
    "    \n",
    "    return rmse, mape, est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
